#!/usr/bin/env python3

# SPDX-FileCopyrightText: Copyright (c) 2025-2026, NVIDIA CORPORATION & AFFILIATES.
# All rights reserved.
# SPDX-License-Identifier: Apache-2.0

import requests
import xmltodict
import yaml

from html.parser import HTMLParser
from pathlib import Path


class TextExtractor(HTMLParser):
    """
    Parses HTML content and collects all text nodes, ignoring tags.
    """

    def __init__(self):
        HTMLParser.__init__(self)
        self.text_parts = []

    def handle_data(self, data):
        stripped = data.strip()
        if stripped:
            self.text_parts.append(stripped)

    def get_text(self):
        return " ".join(self.text_parts)


def get_summary(html_content):
    """
    Returns a 270 character summary from the HTML content of a blog post.
    """
    parser = TextExtractor()
    parser.feed(html_content)
    text = parser.get_text()
    if len(text) > 267:
        return text[:267] + "..."
    return text


def write_posts_to_file(posts):
    """
    Writes the posts data to a YAML file that can be used by Hugo.
    """
    script_path = Path(__file__)
    script_name = script_path.name
    current_dir = script_path.parent
    output_file = current_dir.joinpath("..", "data", "posts", "nvidia.yaml")
    header = "\n".join(
        ["#", f'# This file was automatically generated by "{script_name}"', "#"]
    )
    with open(output_file, "w") as file:
        file.write("\n".join([header, yaml.dump(posts)]))


def main():
    """
    Retrieves latest RAPIDS posts from the NVIDIA Technical Blog Atom feed and
    writes the content to a YAML file that can be used by Hugo.
    """
    headers = {"user-agent": "Mozilla/5.0"}
    response = requests.get(
        "https://developer.nvidia.com/blog/tag/rapids/feed/", headers=headers
    )
    feed = xmltodict.parse(response.content)
    posts = []

    for entry in feed["feed"]["entry"]:
        post = {}
        post["title"] = entry["title"]["#text"]
        # The alternate link may be a list or a single dict depending on xmltodict
        links = entry["link"]
        if isinstance(links, list):
            link = next(
                (lnk["@href"] for lnk in links if lnk.get("@rel") == "alternate"),
                links[0]["@href"],
            )
        else:
            link = links["@href"]
        post["link"] = link
        author = entry.get("author", {})
        post["poster"] = author.get("name", "")
        post["date"] = entry["published"]
        summary_html = entry.get("summary", {})
        if isinstance(summary_html, dict):
            summary_html = summary_html.get("#text", "")
        post["text"] = get_summary(summary_html)
        posts.append(post)

    write_posts_to_file(posts)


if __name__ == "__main__":
    main()
